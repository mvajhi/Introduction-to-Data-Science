{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecfbb4b0c704e67",
   "metadata": {},
   "source": [
    "# Web Scraping and Introductory Data Analysis\n",
    "\n",
    "Welcome to Homework 0, where we will delve into web scraping and perform an introductory data analysis. This homework will be a hands-on exercise that will help you become familiar with the process of extracting data from websites and conducting basic statistical analysis. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this homework, you will be able to:\n",
    "\n",
    "1. Set up a Python environment with the necessary libraries for web scraping and data analysis.\n",
    "2. Write a web scraping script using Beautiful Soup and Selenium to collect data from a website.\n",
    "3. Sample from the collected dataset and compare the statistics of the sample and the population.\n",
    "   \n",
    "## Tasks\n",
    "\n",
    "1. **Environment Setup**: Install the required libraries such as Beautiful Soup, Selenium, pandas, numpy, matplotlib, and seaborn.\n",
    "\n",
    "2. **Web Scraping**: Write a script to scrape transaction data from [Etherscan.io](https://etherscan.io/txs). Use Selenium to interact with the website and Beautiful Soup to parse the HTML content.\n",
    "\n",
    "3. **Data Sampling**: Once the data is collected, create a sample from the dataset. Compare the sample statistics (mean and standard deviation) with the population statistics.\n",
    "\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. A Jupyter notebook with all the code and explanations.\n",
    "2. A detailed report on the findings, including the comparison of sample and population statistics.\n",
    "Note: You can include the report in your notebook.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Begin by setting up your Python environment and installing the necessary libraries. Then, proceed with the web scraping task, ensuring that you handle any potential issues such as rate limiting. Once you have the data, move on to the data sampling and statistical analysis tasks. \n",
    "\n",
    "Remember to document your process and findings in the Jupyter notebook, and to include visualizations where appropriate to illustrate your results. <br>\n",
    "Good luck, and happy scraping!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca352a49724d191",
   "metadata": {},
   "source": [
    "## Data Collection (Etherscan)\n",
    "\n",
    "In this section, we will use web scraping to gather transaction data from the Ethereum blockchain using the Etherscan block explorer. Our objective is to collect transactions from the **last 10 blocks** on Ethereum.\n",
    "\n",
    "To accomplish this task, we will employ web scraping techniques to extract the transaction data from the Etherscan website. The URL we will be targeting for our data collection is:\n",
    "\n",
    "[https://etherscan.io/txs](https://etherscan.io/txs)\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Navigate to the URL**: Use Selenium to open the Etherscan transactions page in a browser.\n",
    "\n",
    "2. **Locate the Transaction Data**: Identify the HTML elements that contain the transaction data for the specified block range.\n",
    "\n",
    "3. **Extract the Data**: Write a script to extract the transaction details e.g. Hash, Method, Block, etc.\n",
    "\n",
    "4. **Handle Pagination**: If the transactions span multiple pages, implement pagination handling to navigate through the pages and collect all relevant transaction data.\n",
    "\n",
    "5. **Store the Data**: Save the extracted transaction data into a structured format, such as a CSV file or a pandas DataFrame, for further analysis.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Rate Limiting**: Be mindful of the website's rate limits to avoid being blocked. Implement delays between requests if necessary.\n",
    "- **Dynamic Content**: The Etherscan website may load content dynamically. Ensure that Selenium waits for the necessary elements to load before attempting to scrape the data.\n",
    "- **Data Cleaning**: After extraction, clean the data to remove any inconsistencies or errors that may have occurred during the scraping process.\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Ethereum](https://ethereum.org/en/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54fa10db-ec9e-4921-870a-50066926ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The geckodriver version (0.33.0) detected in PATH at /usr/local/bin/geckodriver might not be compatible with the detected firefox version (123.0); currently, geckodriver 0.34.0 is recommended for firefox 123.*, so it is advised to delete the driver in PATH and retry\n"
     ]
    }
   ],
   "source": [
    "# Generated by Selenium IDE\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"https://etherscan.io/txs\")\n",
    "the_soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d507b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = the_soup.find(\"tbody\", attrs={\"class\":\"align-middle text-nowrap\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf12ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tr>\\n<td><button class=\"js-tnx-preview btn btn-sm btn-white fs-70x content-center mx-auto myFnExpandBox\" data-bs-container=\"body\" data-bs-content=\"&lt;i class=\\'fas fa-circle-notch fa-spin text-primary fa-2x\\'&gt;&lt;/i&gt;\" data-bs-content-id=\"js-tnx-preview\" data-bs-custom-class=\"popover-preview\" data-bs-html=\"true\" data-bs-placement=\"right\" data-bs-toggle=\"popover\" data-bs-trigger=\"manual\" data-i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = [i for i in t.children]\n",
    "str(row[1])[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e85c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Transfer\n",
      "2 Transfer*\n",
      "3 Transfer\n",
      "4 Transfer\n",
      "5 Transfer*\n",
      "6 Relay\n",
      "7 Transfer*\n",
      "8 Exec Transaction\n",
      "9 Transfer\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(i, row[i].findAll(\"td\")[2].find(\"span\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbba4818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Txn Hash': '0x5830f362d58d12323ebad2285016faa45bd25276ab4b76c3bbe80a6f60205a1f',\n",
       " 'Method': 'Transfer',\n",
       " 'Block': '19347624',\n",
       " 'Time': '2024-03-02 12:56:59',\n",
       " 'From': 'Public Tag: beaverbuild<br/>(0x95222290dd7278aa3ddd389cc1e1d165cc4bafe5)',\n",
       " 'Self': False,\n",
       " 'To': '0xd6e4aa932147a3fe5311da1b67d9e73da06f9cef',\n",
       " 'Value': '0.04264153 ETH',\n",
       " 'Txn Fee': '0.00133034',\n",
       " 'GasPrice': '47.24401969',\n",
       " 'Error': ''}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_row_to_dict(row):\n",
    "    cells = row.findAll(\"td\")\n",
    "    return {\"Txn Hash\": cells[1].find(\"a\").text,\n",
    "            \"Method\": cells[2].find(\"span\").text, # TODO cant show full text\n",
    "            \"Block\": cells[3].find(\"a\").text,\n",
    "            \"Time\": cells[4].find(\"span\").text,\n",
    "            \"From\": cells[7].find(\"a\")[\"data-bs-title\"] if cells[7].find(\"a\").has_attr('data-bs-title')\\\n",
    "            else cells[7].find(\"span\")[\"data-bs-title\"],\n",
    "            \"Self\": cells[8].text == \"SELF\",\n",
    "            \"To\": cells[9].find(\"a\")[\"data-bs-title\"] if cells[9].find(\"a\").has_attr('data-bs-title')\\\n",
    "            else cells[9].find(\"span\")[\"data-bs-title\"],\n",
    "            \"Value\": cells[10].text,\n",
    "            \"Txn Fee\": cells[11].text,\n",
    "            \"GasPrice\": cells[12].text,\n",
    "            \"Error\": cells[1].findAll(\"span\")[0][\"data-bs-title\"]\\\n",
    "            if len(cells[1].findAll(\"span\")) > 1 else \"\"}\n",
    "convert_row_to_dict(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef0ad965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "sample row: <tr>\n",
      "<td><button class=\"js-tnx-preview btn btn-sm btn-white fs-70x content-center mx-auto myFnExpandBox\" data-bs-container=\"body\" data-bs-content=\"&lt;i class='fas fa-circle-notch fa-spin text-primary fa-2x'&gt;&lt;/i&gt;\" data-bs-content-id=\"js-tnx-preview\" data-bs-custom-class=\"popover-preview\" da...\n",
      "----------\n",
      "\n",
      "--------\n",
      "sample data: {'Txn Hash': '0xe3afcae50ebd11bcb8dba5637a81b61540e962c107f9b7c5eb8c97ecde6fdfcf', 'Method': 'Transfer*', 'Block': '19347624', 'Time': '2024-03-02 12:56:59', 'From': '0x415c8893d514f9bc5211d36eeda4183226b84aa7', 'Self': False, 'To': '0xff00000000000000000000000000000000081457', 'Value': '0 ETH', 'Txn Fee': '0.09146828', 'GasPrice': '47.25401969', 'Error': ''}\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_transaction(the_soup, log=False):\n",
    "    table = the_soup.find(\"tbody\", attrs={\"class\":\"align-middle text-nowrap\"})\n",
    "    rows = [i for i in table.children]\n",
    "    if log:\n",
    "        print(f\"--------\\nsample row: {str(rows[1])[:300]}...\\n----------\\n\")\n",
    "    row_data = [convert_row_to_dict(rows[i]) for i in range(1, len(rows) - 1)]\n",
    "    if log:\n",
    "        print(f\"--------\\nsample data: {row_data[1]}\\n----------\\n\")\n",
    "    return row_data\n",
    "\n",
    "page_data = parse_transaction(the_soup, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe6f6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_in_json_file(data_list):\n",
    "    json_data = json.dumps(data_list, indent=4)\n",
    "\n",
    "    file_path = f\"data_block_{data_list[0]['Block']}_{data_list[-1]['Block']}.json\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(json_data)\n",
    "\n",
    "    print(f\"Data has been saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c629ab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19347624"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_first_block(the_soup):\n",
    "    return int(parse_transaction(the_soup)[1][\"Block\"])\n",
    "find_first_block(the_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b9f89c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_page_count(the_soup):\n",
    "    return int(the_soup.find(class_=\"page-link text-nowrap\").text.split()[3])\n",
    "get_page_count(the_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_block_data(driver, block):\n",
    "    block_data = list()\n",
    "    driver.get(f\"https://etherscan.io/txs?block={block}\")\n",
    "    the_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    page_count = get_page_count(the_soup)\n",
    "    for i in range(1, page_count + 1):\n",
    "        driver.get(f\"https://etherscan.io/txs?block={block}&p={i}\")\n",
    "        the_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        block_data.extend(parse_transaction(the_soup))\n",
    "    return block_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09bf59ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample block 19347625: {'Txn Hash': '0x9e5e0bb640efeb9e93b51cc5fb25944f11808b29fce206d45d0d9e29774b9c9e', 'Method': 'Transfer', 'Block': '19347625', 'Time': '2024-03-02 12:57:11', 'From': '0x464333b5c19be184573b411b844888e48a9dfb4f', 'Self': False, 'To': '0x764a30e324953e81de15cc0b7dd4f4ca8fafba0a', 'Value': '0.03951573 ETH', 'Txn Fee': '0.00198426', 'GasPrice': '94.48903938', 'Error': ''}\n",
      "\n",
      "sample block 19347624: {'Txn Hash': '0x213b47a13af15a996e75bff14366571659e8b28905c3c0af4ee54bd35f6c332f', 'Method': '0x592982d3', 'Block': '19347624', 'Time': '2024-03-02 12:56:59', 'From': '0xae2fc483527b8ef99eb5d9b44875f005ba1fae13', 'Self': False, 'To': 'Public Tag: MEV Bot: 0x6b7...A80<br/>(0x6b75d8af000000e20b7a7ddf000ba900b4009a80)', 'Value': '0.000000206 ETH', 'Txn Fee': '0.00448246', 'GasPrice': '47.24401969', 'Error': ''}\n",
      "\n",
      "sample block 19347623: {'Txn Hash': '0x87ed4372bf4cc16df5f86a9fb53c03337224103f932828090ba418f1846319c9', 'Method': 'Execute', 'Block': '19347623', 'Time': '2024-03-02 12:56:47', 'From': '0x40ff30dce373c85dc81f648afe80b1dbf5e79c8e', 'Self': False, 'To': 'Public Tag: Uniswap: Universal Router<br/>(0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad)', 'Value': '0 ETH', 'Txn Fee': '0.00616776', 'GasPrice': '49.29672719', 'Error': ''}\n",
      "\n",
      "sample block 19347622: {'Txn Hash': '0x248a4fd5dfd3a65062e9f7d153fe576cb315bc6020d1c1ebf50aaeec5bec9a84', 'Method': 'Execute', 'Block': '19347622', 'Time': '2024-03-02 12:56:35', 'From': '0xf48ff79ee870917fea46ce375b25d4cf745e832f', 'Self': False, 'To': 'Public Tag: Uniswap: Universal Router<br/>(0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad)', 'Value': '0 ETH', 'Txn Fee': '0.01486014', 'GasPrice': '49.82679478', 'Error': ''}\n",
      "\n",
      "sample block 19347621: {'Txn Hash': '0x0d3d212c36d5052c658281bc7c25270cb4f290044ec1c5d5b5580d1ea395406f', 'Method': '0x7c3d7934', 'Block': '19347621', 'Time': '2024-03-02 12:56:23', 'From': '0xae2fc483527b8ef99eb5d9b44875f005ba1fae13', 'Self': False, 'To': 'Public Tag: MEV Bot: 0x6b7...A80<br/>(0x6b75d8af000000e20b7a7ddf000ba900b4009a80)', 'Value': '0.000000036 ETH', 'Txn Fee': '0.00562266', 'GasPrice': '50.72411181', 'Error': ''}\n",
      "\n",
      "sample block 19347620: {'Txn Hash': '0x7782f29d646d46fe5cbb0eac605bf1fd5f637f0140e4d0fc33b210aeb499b800', 'Method': '0x59034948', 'Block': '19347620', 'Time': '2024-03-02 12:56:11', 'From': '0xae2fc483527b8ef99eb5d9b44875f005ba1fae13', 'Self': False, 'To': 'Public Tag: MEV Bot: 0x6b7...A80<br/>(0x6b75d8af000000e20b7a7ddf000ba900b4009a80)', 'Value': '0.000000099 ETH', 'Txn Fee': '0.00678427', 'GasPrice': '46.6780191', 'Error': ''}\n",
      "\n",
      "sample block 19347619: {'Txn Hash': '0x175057d32401d8fcfaeae2fad175498d9d56cac71baf7c387b74deeb820706e1', 'Method': 'Execute', 'Block': '19347619', 'Time': '2024-03-02 12:55:59', 'From': '0xc3aa362caf2c986adf7359a9be00c5fabb013ce4', 'Self': False, 'To': 'Public Tag: Uniswap: Universal Router<br/>(0x3fc91a3afd70395cd496c647d5a6cc9d4b2b7fad)', 'Value': '0.3 ETH', 'Txn Fee': '0.00780583', 'GasPrice': '50.29146221', 'Error': ''}\n",
      "\n",
      "sample block 19347618: {'Txn Hash': '0xecb2f933641cf26d7335ad692a4df429681a0eebc16abc47c52cbbcfa2bf42ec', 'Method': 'Exact Input Sing...', 'Block': '19347618', 'Time': '2024-03-02 12:55:47', 'From': '0xa2f30711143c45482c9ff35c6f1401f90924188a', 'Self': False, 'To': 'Public Tag: Uniswap V3: Router<br/>(0xe592427a0aece92de3edee1f18e0157c05861564)', 'Value': '0 ETH', 'Txn Fee': '0.01282972', 'GasPrice': '106.2072257', 'Error': ''}\n",
      "\n",
      "sample block 19347617: {'Txn Hash': '0x8c58336c96c54d8cb1ea1a2f7941f940e0de8c612001423083f988597c28a422', 'Method': 'Transfer', 'Block': '19347617', 'Time': '2024-03-02 12:55:35', 'From': '0x501a2b64afa03074472b6cec9293c2395e48e2b2', 'Self': False, 'To': 'Public Tag: Tether: USDT Stablecoin<br/>(0xdac17f958d2ee523a2206206994597c13d831ec7)', 'Value': '0 ETH', 'Txn Fee': '0.00262975', 'GasPrice': '57.03339447', 'Error': ''}\n",
      "\n",
      "sample block 19347616: {'Txn Hash': '0xec91672e00ee58324ffa9e3cfedfb272a658228095164ba8c75b379298f27e73', 'Method': '0x28a00911', 'Block': '19347616', 'Time': '2024-03-02 12:55:23', 'From': '0x1111e3ef0b6ae32e14a55e0e7cd9b8505177c2bf', 'Self': False, 'To': 'Public Tag: MEV Bot: 0x000...1d3<br/>(0x000000d40b595b94918a28b27d1e2c66f43a51d3)', 'Value': '72 wei', 'Txn Fee': '0.00970841', 'GasPrice': '47.62293545', 'Error': ''}\n",
      "\n",
      "Data has been saved to data_block_19347625_19347616.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "BLOCK_COUNT = 10\n",
    "def scrape_data(driver):\n",
    "    output = list()\n",
    "    driver.get(\"https://etherscan.io/txs\")\n",
    "    the_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    first_block = find_first_block(the_soup)\n",
    "    for i in range(BLOCK_COUNT):\n",
    "        output.extend(collect_block_data(driver, first_block - i))\n",
    "        print(f\"sample block {first_block - i}: {output[-1]}\\n\")\n",
    "        time.sleep(1)\n",
    "    write_in_json_file(output)\n",
    "scrape_data(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a013b104d142cfc",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that we have collected the transaction data from Etherscan, the next step is to perform conduct an initial analysis. This task will involve the following steps:\n",
    "\n",
    "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
    "\n",
    "2. **Data Cleaning**: Clean the data by converting data types, removing any irrelevant information, and handling **duplicate** values.\n",
    "\n",
    "3. **Statistical Analysis**: Calculate the mean and standard deviation of the population. Evaluate these statistics to understand the distribution of transaction values. The analysis and plotting will be on **Txn Fee** and **Value**.\n",
    "\n",
    "4. **Visualization**: This phase involves the creation of visual representations to aid in the analysis of transaction values. The visualizations include:\n",
    "    - A histogram for each data column, which provides a visual representation of the data distribution. The selection of bin size is crucial and should be based on the data's characteristics to ensure accurate representation. Provide an explanation on the bin size selection!\n",
    "    - A normal distribution plot fitted alongside the histogram to compare the empirical distribution of the data with the theoretical normal distribution.\n",
    "    - A box plot and a violin plot to identify outliers and provide a comprehensive view of the data's distribution.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "The project aims to deliver the following deliverables:\n",
    "\n",
    "- A refined pandas DataFrame containing the transaction data, which has undergone thorough cleaning and is ready for analysis.\n",
    "- A simple statistical analysis evaluating the population statistics, offering insights into the distribution of transaction values and fees.\n",
    "- A set of visualizations showcasing the distribution of transaction values for the population. These visualizations include histograms, normal distribution plots, box plots, and violin plots, each serving a specific purpose in the analysis.\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "The project starts with the importing of transaction data into a pandas DataFrame, setting the stage for data manipulation and analysis. Subsequent steps involve the cleaning of the data to ensure its quality and reliability. Followed by the calculation of population statistics. Finally, a series of visualizations are created to visually analyze the distribution of transaction values and fees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f481b11a08d876b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T14:02:12.152030482Z",
     "start_time": "2024-02-25T14:02:12.101846096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87030e5e0b4fe1e6",
   "metadata": {},
   "source": [
    "## Data Sampling and Analysis\n",
    "\n",
    "In this section, we will delve into the process of data sampling and perform an initial analysis on the transaction data we have collected. Our objective is to understand the distribution of transaction values by sampling the data and comparing the sample statistics with the population statistics.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Load the Data**: Import the collected transaction data into a pandas DataFrame.\n",
    "\n",
    "2. **Data Cleaning**: Clean the data by handling missing values, converting data types, and removing any irrelevant information.\n",
    "\n",
    "3. **Simple Random Sampling (SRS)**: Create a sample from the dataset using a simple random sampling method. This involves randomly selecting a subset of the data without regard to any specific characteristics of the data.\n",
    "\n",
    "4. **Stratified Sampling**: Create another sample from the dataset using a stratified sampling method. This involves dividing the data into strata based on a specific characteristic (e.g., transaction value) and then randomly selecting samples from each stratum. Explain what you have stratified the data by and why you chose this column.\n",
    "\n",
    "5. **Statistical Analysis**: Calculate the mean and standard deviation of the samples and the population. Compare these statistics to understand the distribution of transaction values.\n",
    "\n",
    "6. **Visualization**: Plot the distribution of transaction values and fees for both the samples and the population to visually compare their distributions.\n",
    "\n",
    "### Considerations\n",
    "\n",
    "- **Sample Size**: The size of the sample should be large enough to represent the population accurately but not so large that it becomes impractical to analyze.\n",
    "- **Sampling Method**: Choose the appropriate sampling method based on the characteristics of the data and the research question.\n",
    "\n",
    "Explain the above considerations in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f6becd41f9b2393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T19:36:26.333480965Z",
     "start_time": "2024-02-27T19:36:26.324023052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
